{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "black-sodium",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "#!pip install -U sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "signal-narrow",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Класс предсказания состояний на основе RDF\n",
    "class DesignForestModel():\n",
    "    def __init__(self):\n",
    "        self.df = pd.read_csv('lander_data.csv').head(2000)\n",
    "        self.seed = 50\n",
    "        self.model = self._learn_model()\n",
    "        \n",
    "    # Обучение модели\n",
    "    def _learn_model(self):\n",
    "        # Выбираем найзвания столбцов из датасета\n",
    "        X = self.df[['X', 'Y', 'VelX', 'VelY', 'Angle', 'AngularVel', 'ActionID']]\n",
    "        y = np.array([int(abs(self.df['ResX'][i]) * 100000) + int(abs(self.df['Angle'][i]) * 100000) \n",
    "                           for i in range(len(self.df[['ResX']]))])\n",
    "        # 70% выборки идёт на обучение \n",
    "        train_X, test_X, train_y, test_y = train_test_split(X, y,\n",
    "                                                 test_size = 0.3, \n",
    "                                                 random_state = self.seed)\n",
    "\n",
    "        # Создаём модель леса из 100 деревьев\n",
    "        model = RandomForestClassifier(n_estimators = 100,\n",
    "                                       random_state = self.seed,\n",
    "                                       max_features = 'sqrt',\n",
    "                                       n_jobs = -1,\n",
    "                                       verbose = 0)\n",
    "\n",
    "        # Обучение модели на тренировочных данных \n",
    "        model.fit(train_X, train_y)\n",
    "        return model\n",
    "    \n",
    "    # Метод предсказания состояния при воздействии на текущее состояние\n",
    "    # Вход:  DataFrame из состояния + действие\n",
    "    # Выход: DataFrame из предсказанных состояний (X, alpha)\n",
    "    def GetNextStates(self, current_states):\n",
    "        prediction = self.model.predict(current_states)\n",
    "        return prediction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "experienced-proposal",
   "metadata": {},
   "outputs": [],
   "source": [
    "from abc import ABCMeta, abstractmethod\n",
    "# Абстрактный класс подбора оптимального управления\n",
    "class ASolver():\n",
    "    __metaclass__ = ABCMeta\n",
    "    \n",
    "    @abstractmethod\n",
    "    def Solve(state):\n",
    "        \"\"\" Подбор оптимального действия по текущему состоянию \"\"\"\n",
    "        \n",
    "\n",
    "# Класс подбора оптимального управления\n",
    "class Solver_v1(ASolver):\n",
    "    def __init__(self, forestModel : DesignForestModel):\n",
    "        self.forestModel = forestModel\n",
    "        \n",
    "    # Подбор оптимального действия по текущему состоянию\n",
    "    # Вход:  состояние\n",
    "    # Выход: действие\n",
    "    def Solve(self, state):\n",
    "        df = pd.DataFrame(index = [0, 1, 2, 3], columns = ['X', 'Y', 'VelX', 'VelY', 'Angle', 'AngylarVel', 'ActionID'])\n",
    "        for i in range(4):\n",
    "            for j in range(7):\n",
    "                df.loc[i][j] = state[j] if j != 6 else i\n",
    "        \n",
    "        prediction = self.forestModel.GetNextStates(df)\n",
    "        action = np.argmin([abs(prediction) for i in range(4)])\n",
    "        return action\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "drawn-electric",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Класс модуля управления\n",
    "class ControlModule():\n",
    "    def __init__(self):\n",
    "        None\n",
    "        \n",
    "    # Метод получения управления от состояния\n",
    "    # Вход:  сотояние и алгоритм решения\n",
    "    # Выход: действие, полученное алгоритмом\n",
    "    def GetControl(self, state, solver : ASolver):\n",
    "        self.solver = solver\n",
    "        action = self.solver.Solve(state)\n",
    "        return action\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "thousand-briefs",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Клиентский код\n",
    "#!pip install -U gym\n",
    "import gym\n",
    "\n",
    "# Инициализируем среду\n",
    "env = gym.make('LunarLander-v2')\n",
    "# Количество запусков игры\n",
    "count_of_episodes = 5\n",
    "# Максимальное количество итераций в запуске\n",
    "count_of_steps = 200\n",
    "\n",
    "# Дерево решений\n",
    "tree_forest = DesignForestModel()\n",
    "# Объект класса поиска управления\n",
    "solver = Solver_v1(tree_forest)\n",
    "# Объект модуля управления\n",
    "control_module = ControlModule()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "elegant-northern",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 0 finished with reward: 18.104202799707167\n",
      "Episode 1 finished with reward: -26.98062618867931\n",
      "Episode 2 finished with reward: 38.15045347306048\n",
      "Episode 3 finished with reward: 6.526589442093325\n",
      "Episode 4 finished with reward: 8.011861570816706\n"
     ]
    }
   ],
   "source": [
    "for i_episode in range(count_of_episodes):\n",
    "        cur_reward = 0\n",
    "        observation = env.reset()\n",
    "        for step_ind in range(count_of_steps):\n",
    "            env.render()\n",
    "            if(step_ind % 2 == 0):\n",
    "                action = control_module.GetControl(observation[0:6], solver)\n",
    "            else:\n",
    "                action = 0\n",
    "            \n",
    "            observation, reward, done, info = env.step(action)\n",
    "            \n",
    "            if done:\n",
    "                print(\"Episode {} finished with reward: {}\".format(i_episode, cur_reward))\n",
    "                break\n",
    "            else:\n",
    "                cur_reward = reward\n",
    "env.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
